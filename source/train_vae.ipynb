{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "basic-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from vae import VAE\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proper-credit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 64    #32\n",
    "NUM_EPOCHS = 16   #100\n",
    "SPECTROGRAMS_PATH = \"C:\\\\Users\\\\pbeata\\\\Desktop\\\\Data_Science\\\\Audio\\\\sound-generation\\\\datasets\\\\fsdd\\\\spectrograms\\\\\"\n",
    "\n",
    "\n",
    "# choose dataset\n",
    "run_mnist = False\n",
    "run_fsdd = True\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # apply normalization\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    # add channel dimension\n",
    "    x_train = x_train.reshape(x_train.shape + (1,))\n",
    "    x_test = x_test.reshape(x_test.shape + (1,))\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file in file_names:\n",
    "            file_path = os.path.join(root, file)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames) only 2D \n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    # we need to add a channel dimension before returning x_train\n",
    "    x_train = x_train[..., np.newaxis] # --> (3000, 256, 64, 1)\n",
    "    return x_train\n",
    "\n",
    "\n",
    "def train_mnist(x_train, learning_rate, batch_size, num_epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(28, 28, 1),\n",
    "        conv_filters=(32, 64, 64, 64),\n",
    "        conv_kernels=(3, 3, 3, 3),\n",
    "        conv_strides=(1, 2, 2, 1),\n",
    "        latent_space_dim=2\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, num_epochs)\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "def train_fsdd(x_train, learning_rate, batch_size, num_epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 64, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "        latent_space_dim=128\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, num_epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-apparatus",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appreciated-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_mnist:\n",
    "\n",
    "    # train VAE on subset of the MNIST dataset\n",
    "    num_samples = 10_000\n",
    "    x_train, _, _, _ = load_mnist()\n",
    "    autoencoder = train_mnist(x_train[:num_samples], LEARNING_RATE, BATCH_SIZE, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contained-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_mnist:\n",
    "\n",
    "    # save and re-load the VAE model\n",
    "    folder_path = \"../trained_models/vae_model/\"\n",
    "    autoencoder.save(folder_path)\n",
    "    autoencoder2 = VAE.load(folder_path)\n",
    "    autoencoder2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-philip",
   "metadata": {},
   "source": [
    "### FSDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-metallic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 256, 64, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D)   (None, 128, 32, 512) 5120        encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_1 (ReLU)           (None, 128, 32, 512) 0           encoder_conv_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_1 (BatchNormalizatio (None, 128, 32, 512) 2048        encoder_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D)   (None, 64, 16, 256)  1179904     encoder_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_2 (ReLU)           (None, 64, 16, 256)  0           encoder_conv_layer_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_2 (BatchNormalizatio (None, 64, 16, 256)  1024        encoder_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D)   (None, 32, 8, 128)   295040      encoder_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_3 (ReLU)           (None, 32, 8, 128)   0           encoder_conv_layer_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_3 (BatchNormalizatio (None, 32, 8, 128)   512         encoder_relu_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D)   (None, 16, 4, 64)    73792       encoder_bn_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_4 (ReLU)           (None, 16, 4, 64)    0           encoder_conv_layer_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_4 (BatchNormalizatio (None, 16, 4, 64)    256         encoder_relu_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_5 (Conv2D)   (None, 8, 4, 32)     18464       encoder_bn_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_5 (ReLU)           (None, 8, 4, 32)     0           encoder_conv_layer_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_5 (BatchNormalizatio (None, 8, 4, 32)     128         encoder_relu_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           encoder_bn_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 128)          131200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 128)          131200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 128)          0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,838,688\n",
      "Trainable params: 1,836,704\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 16, 4, 32)         9248      \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 16, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 16, 4, 32)         128       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 32, 8, 64)         18496     \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 32, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 32, 8, 64)         256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 64, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "decoder_relu_3 (ReLU)        (None, 64, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 64, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 128, 32, 256)      295168    \n",
      "_________________________________________________________________\n",
      "decoder_relu_4 (ReLU)        (None, 128, 32, 256)      0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_4 (BatchNormaliza (None, 128, 32, 256)      1024      \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 256, 64, 1)        2305      \n",
      "_________________________________________________________________\n",
      "sigmoid_layer (Activation)   (None, 256, 64, 1)        0         \n",
      "=================================================================\n",
      "Total params: 533,089\n",
      "Trainable params: 532,129\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 256, 64, 1)]      0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 128)               1838688   \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 256, 64, 1)        533089    \n",
      "=================================================================\n",
      "Total params: 2,371,777\n",
      "Trainable params: 2,368,833\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n",
      "Train on 3000 samples\n",
      "Epoch 1/16\n",
      "3000/3000 [==============================] - 1367s 456ms/sample - loss: 120638.0210 - _calculate_reconstruction_loss: 0.1198 - _calculate_KL_loss: 876.0431\n",
      "Epoch 2/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1311s 437ms/sample - loss: 32965.6628 - _calculate_reconstruction_loss: 0.0324 - _calculate_KL_loss: 541.0589\n",
      "Epoch 3/16\n",
      "3000/3000 [==============================] - 1202s 401ms/sample - loss: 20320.6214 - _calculate_reconstruction_loss: 0.0199 - _calculate_KL_loss: 413.3011\n",
      "Epoch 4/16\n",
      "3000/3000 [==============================] - 958s 319ms/sample - loss: 14743.4514 - _calculate_reconstruction_loss: 0.0144 - _calculate_KL_loss: 296.5644\n",
      "Epoch 5/16\n",
      "3000/3000 [==============================] - 983s 328ms/sample - loss: 13154.4497 - _calculate_reconstruction_loss: 0.0129 - _calculate_KL_loss: 267.3060\n",
      "Epoch 6/16\n",
      "3000/3000 [==============================] - 995s 332ms/sample - loss: 12370.7108 - _calculate_reconstruction_loss: 0.0121 - _calculate_KL_loss: 249.1351\n",
      "Epoch 7/16\n",
      "3000/3000 [==============================] - 974s 325ms/sample - loss: 11943.7226 - _calculate_reconstruction_loss: 0.0117 - _calculate_KL_loss: 239.9413\n",
      "Epoch 8/16\n",
      "3000/3000 [==============================] - 922s 307ms/sample - loss: 11769.4016 - _calculate_reconstruction_loss: 0.0115 - _calculate_KL_loss: 235.6451\n",
      "Epoch 9/16\n",
      "3000/3000 [==============================] - 904s 301ms/sample - loss: 11482.0988 - _calculate_reconstruction_loss: 0.0113 - _calculate_KL_loss: 231.2261\n",
      "Epoch 10/16\n",
      "3000/3000 [==============================] - 916s 305ms/sample - loss: 11346.4259 - _calculate_reconstruction_loss: 0.0111 - _calculate_KL_loss: 227.5471\n",
      "Epoch 11/16\n",
      "3000/3000 [==============================] - 916s 305ms/sample - loss: 11221.4600 - _calculate_reconstruction_loss: 0.0110 - _calculate_KL_loss: 228.1539\n",
      "Epoch 12/16\n",
      "3000/3000 [==============================] - 918s 306ms/sample - loss: 11228.0892 - _calculate_reconstruction_loss: 0.0110 - _calculate_KL_loss: 226.4986\n",
      "Epoch 13/16\n",
      "3000/3000 [==============================] - 919s 306ms/sample - loss: 11130.0816 - _calculate_reconstruction_loss: 0.0109 - _calculate_KL_loss: 222.3337\n",
      "Epoch 14/16\n",
      "3000/3000 [==============================] - 919s 306ms/sample - loss: 11051.3081 - _calculate_reconstruction_loss: 0.0108 - _calculate_KL_loss: 222.7242\n",
      "Epoch 15/16\n",
      "3000/3000 [==============================] - 918s 306ms/sample - loss: 11025.7078 - _calculate_reconstruction_loss: 0.0108 - _calculate_KL_loss: 222.2912\n",
      "Epoch 16/16\n",
      "3000/3000 [==============================] - 917s 306ms/sample - loss: 11006.2078 - _calculate_reconstruction_loss: 0.0108 - _calculate_KL_loss: 222.1051\n"
     ]
    }
   ],
   "source": [
    "if run_fsdd:\n",
    "\n",
    "    # train VAE on the FSDD dataset (audio files)\n",
    "    x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "    autoencoder = train_fsdd(x_train, LEARNING_RATE, BATCH_SIZE, NUM_EPOCHS)\n",
    "\n",
    "    # save the trained model at the end\n",
    "    save_path = \"../trained_models/vae_model_fsdd/\"\n",
    "    autoencoder.save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
